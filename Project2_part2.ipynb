{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbc15df1-3c78-475e-a43c-15a44bdd999b",
   "metadata": {},
   "source": [
    "Project: **Machine Learning Programming Project 2 Part 2** \n",
    "<br>\n",
    "Team Members: **Debit Paudel, Kushal Dahal**\n",
    "<br>\n",
    "We have used github for the collaboration.\n",
    "<br>\n",
    "Github Link: https://github.com/debit7/Bayes_Algorithm_ML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276478fe-0d0b-40d6-a356-faa2046decbb",
   "metadata": {},
   "source": [
    "While looking at the dataset provided by the analytics department with the hits for every hour of the first month, we can see that on the last 5-6 days, the hits are larger as compared to the previous days. We think when one person read the blog and like it, he/she may refer to other friends. So looking at the data, we can say that \"word of mouth\" may have a significant role to increase the hits. Also, we can assume that more people are reading the blog as more longer it is active. Hence, we can expect more traffic in the future rather than this first month. After visualizing the growth of hits and predicting the future hits building a linear regression model, we will be statistically clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "90967095-0386-469b-ab6b-1ab6af7c4dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier                                           Messages\n",
       "0        ham  Go until jurong point, crazy.. Available only ...\n",
       "1        ham                      Ok lar... Joking wif u oni...\n",
       "2       spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3        ham  U dun say so early hor... U c already then say...\n",
       "4        ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "with open('spam.data') as f:\n",
    "        lst = []\n",
    "        for ele in f:\n",
    "            line = ele.replace('\\n','').split('\\t')\n",
    "            \n",
    "            lst.append(line)\n",
    "Headers=['Classifier','Messages']\n",
    "df = pd.DataFrame(lst,columns =Headers) \n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7d9fdde0-96a6-4c13-97d9-e04f33447335",
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomly splitting data in training and testing data set\n",
    "training = df.sample(frac=0.75)\n",
    "testing = df.drop(training.index)\n",
    "#print(training)\n",
    "#print(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2bd52143-6c0c-4c6a-809f-31526536da3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing punctuations from the messages and converting the upper cases to lower case\n",
    "punctuations='''€˜%^&\"\\,!*_~)(-[};:]{'<#£$>./?@+'''\n",
    "stop_words=[\"i\",\"da\",\"we\",\"ur\" ,\"u\",\"am\",\"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
    "wordlist=[]\n",
    "for message in training['Messages']:\n",
    "    \n",
    "    #print(message,'\\n')\n",
    "    for alpha in message:\n",
    "        if alpha in punctuations:\n",
    "            message = message.replace(alpha, \" \")\n",
    "    #for lower case        \n",
    "    message=message.lower()\n",
    "    \n",
    "    #for stop words\n",
    "    message=message.split()\n",
    "    #print(message)\n",
    "    for word in message:\n",
    "        if word in stop_words:\n",
    "            #print(word,'\\n')\n",
    "            message.remove(word)\n",
    "        wordlist.append(word)\n",
    "wordlist=list(set(wordlist))\n",
    "Vocabulary = len(wordlist) \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "0231b638-71f7-435a-9574-fe51fef82f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating frequency for each word in a message\n",
    "word_counts_per_Messages=[\n",
    "    [row[1].count(word) for word in wordlist]\n",
    "    for _, row in training.iterrows()]\n",
    "df_wordcount=pd.DataFrame(word_counts_per_Messages,columns=wordlist)\n",
    "training = pd.concat([training.reset_index(), df_wordcount], axis=1).iloc[:,1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "ab454ad3-2033-4fc7-980b-a3bc1019cddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_probability = training['Classifier'].value_counts()['spam'] / len(training)\n",
    "ham_probability = training['Classifier'].value_counts()['ham'] / len(training)\n",
    "spam_list=training['Classifier'] == 'spam'\n",
    "ham_list=training['Classifier'] == 'ham'\n",
    "spam = training[training['Classifier'] == 'spam']\n",
    "ham = training[training['Classifier'] == 'ham']\n",
    "spam_n = training.loc[spam_list, 'Messages'].apply(len).sum()\n",
    "ham_n = training.loc[ham_list, 'Messages'].apply(len).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "0dc1795b-a9ef-409a-a848-706ff283f0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_word_spam(word):\n",
    "        return (spam[word].sum() + 1) / (spam_n + Vocabulary) if word in training.columns else 1\n",
    "   \n",
    "def probability_word_ham(word):\n",
    "        return (ham[word].sum() + 1) / (ham_n + Vocabulary) if word in training.columns else 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "76c1e5a5-ab91-48a2-a017-2789bad7becb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math as mt\n",
    "def naive_classifier(Message):\n",
    "    prob_spam = spam_probability\n",
    "    prob_ham = ham_probability\n",
    "    for word in Message:\n",
    "        prob_spam += mt.log(probability_word_spam(word),10)\n",
    "        prob_ham += mt.log(probability_word_ham(word),10)\n",
    "    prob_spam=10**prob_spam\n",
    "    prob_ham=10**prob_ham\n",
    "    return 'ham' if prob_ham > prob_spam else 'spam'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "5807acb0-f24b-49cf-8beb-a84e2bd9b381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of this model: 96.12625538020086\n"
     ]
    }
   ],
   "source": [
    "testing['Predicted_label'] = testing['Messages'].apply(naive_classifier)\n",
    "Accuracy = (testing['Predicted_label'] == testing['Classifier']).sum() / len(test) * 100\n",
    "print(\"Accuracy of this model:\",Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4cae4c-2f51-4c81-b3e4-081590eeb406",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
